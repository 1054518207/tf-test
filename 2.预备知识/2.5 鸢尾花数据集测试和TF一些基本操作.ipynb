{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# 导入所需模块\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "# jupyter 进行matplotlib 展示需要引入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 666 # 设置随机化种子，全局一致\n",
    "LEARNING_RATE = 0.01 # 学习率\n",
    "# 导入数据，分别为输入特征和标签\n",
    "x_data = datasets.load_iris().data   # 导入鸢尾花数据\n",
    "y_data = datasets.load_iris().target # 鸢尾花数据集标签\n",
    "\n",
    "# 随机打乱数据，注意使用相同的种子，以便数据和标签一一对应\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(y_data)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将打乱后的顺序分割为训练集和测试集，训练集是前120行数据，测试集是后30行数据\n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用TF的 `cast` 函数转换数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
    "\n",
    "```(python)\n",
    "tf.cast(\n",
    "    x, dtype, name=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.cast(x_train, dtype=tf.float32)\n",
    "x_test = tf.cast(x_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切分传入张量的第一维度，生成输入特征/标签对，构造数据集\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices(('输入特征', '输入标签'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
    "# 用tf.Variable()标记参数可训练\n",
    "# 使用seed使每次生成的随机数相同\n",
    "w1 = tf.Variable(tf.random.truncated_normal(shape=[4,3],stddev=0.1))\n",
    "b1 = tf.Variable(tf.random.truncated_normal(shape=[3],stddev=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.random.truncated_normal\n",
    "\n",
    "生成正态分布函数，超出 $2\\sigma$ 则重新生成该处值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_results = [] # 存放loss变化值，便于生成图片\n",
    "test_acc = []          # 准去率acc变化值，便于生成图片\n",
    "epoch = 500            # 迭代轮次，此处以epoch为结束条件，不是loss变化率\n",
    "loss_all = 0           # 每轮分4个step，loss_all记录四个step生成的4个loss的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.2141112983226776\n",
      "Test_acc: 0.3333333333333333\n",
      "--------------------------\n",
      "Epoch 1, loss: 0.20604370161890984\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 2, loss: 0.2009516842663288\n",
      "Test_acc: 0.3\n",
      "--------------------------\n",
      "Epoch 3, loss: 0.19747979566454887\n",
      "Test_acc: 0.26666666666666666\n",
      "--------------------------\n",
      "Epoch 4, loss: 0.19488252326846123\n",
      "Test_acc: 0.26666666666666666\n",
      "--------------------------\n",
      "Epoch 5, loss: 0.1927838809788227\n",
      "Test_acc: 0.26666666666666666\n",
      "--------------------------\n",
      "Epoch 6, loss: 0.19099611788988113\n",
      "Test_acc: 0.26666666666666666\n",
      "--------------------------\n",
      "Epoch 7, loss: 0.18942121788859367\n",
      "Test_acc: 0.43333333333333335\n",
      "--------------------------\n",
      "Epoch 8, loss: 0.1880033016204834\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 9, loss: 0.18670668452978134\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 10, loss: 0.18550599738955498\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 11, loss: 0.18438197299838066\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 12, loss: 0.18331940099596977\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 13, loss: 0.182306207716465\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 14, loss: 0.18133286386728287\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 15, loss: 0.18039192259311676\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 16, loss: 0.17947762832045555\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 17, loss: 0.17858561500906944\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 18, loss: 0.1777125671505928\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 19, loss: 0.17685601860284805\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 20, loss: 0.17601412907242775\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 21, loss: 0.17518553137779236\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 22, loss: 0.17436925321817398\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 23, loss: 0.17356451600790024\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 24, loss: 0.17277078330516815\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 25, loss: 0.1719876490533352\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 26, loss: 0.17121479660272598\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 27, loss: 0.17045198753476143\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 28, loss: 0.1696990467607975\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 29, loss: 0.16895581781864166\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 30, loss: 0.16822217032313347\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 31, loss: 0.16749799624085426\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 32, loss: 0.16678320243954659\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 33, loss: 0.16607770696282387\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 34, loss: 0.16538138315081596\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 35, loss: 0.1646941900253296\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 36, loss: 0.1640160195529461\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 37, loss: 0.1633467972278595\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 38, loss: 0.16268642619252205\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 39, loss: 0.1620348021388054\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 40, loss: 0.16139186173677444\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 41, loss: 0.16075748950242996\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 42, loss: 0.16013159230351448\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 43, loss: 0.15951408445835114\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 44, loss: 0.15890486538410187\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 45, loss: 0.15830381214618683\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 46, loss: 0.15771084278821945\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 47, loss: 0.15712585300207138\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 48, loss: 0.15654872357845306\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 49, loss: 0.15597935393452644\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 50, loss: 0.15541763976216316\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 51, loss: 0.15486346557736397\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 52, loss: 0.1543167270720005\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 53, loss: 0.1537773236632347\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 54, loss: 0.15324513614177704\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 55, loss: 0.15272006392478943\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 56, loss: 0.15220200270414352\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 57, loss: 0.15169082209467888\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 58, loss: 0.15118643268942833\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 59, loss: 0.15068873018026352\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 60, loss: 0.1501975916326046\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 61, loss: 0.1497129276394844\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 62, loss: 0.14923463016748428\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 63, loss: 0.14876258745789528\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 64, loss: 0.14829669147729874\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 65, loss: 0.1478368565440178\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 66, loss: 0.1473829783499241\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 67, loss: 0.14693495631217957\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 68, loss: 0.14649267867207527\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 69, loss: 0.14605605974793434\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 70, loss: 0.14562499895691872\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 71, loss: 0.14519941434264183\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 72, loss: 0.14477919414639473\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 73, loss: 0.14436424896121025\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 74, loss: 0.14395450055599213\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 75, loss: 0.1435498483479023\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 76, loss: 0.1431502029299736\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 77, loss: 0.14275548234581947\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 78, loss: 0.14236559718847275\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 79, loss: 0.14198046922683716\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 80, loss: 0.14160000160336494\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 81, loss: 0.14122412726283073\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 82, loss: 0.14085275307297707\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 83, loss: 0.14048581942915916\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 84, loss: 0.14012322574853897\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 85, loss: 0.139764916151762\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 86, loss: 0.13941079378128052\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 87, loss: 0.13906080275774002\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 88, loss: 0.13871487230062485\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 89, loss: 0.13837292045354843\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 90, loss: 0.1380348764359951\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 91, loss: 0.13770068064332008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 92, loss: 0.1373702622950077\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 93, loss: 0.1370435580611229\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 94, loss: 0.13672048598527908\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 95, loss: 0.1364010088145733\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 96, loss: 0.13608505204319954\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 97, loss: 0.13577255979180336\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 98, loss: 0.13546346127986908\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 99, loss: 0.13515769690275192\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 100, loss: 0.1348552256822586\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 101, loss: 0.13455597311258316\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 102, loss: 0.1342598982155323\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 103, loss: 0.13396693393588066\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 104, loss: 0.13367702811956406\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 105, loss: 0.1333901360630989\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 106, loss: 0.13310620188713074\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 107, loss: 0.13282517343759537\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 108, loss: 0.13254700601100922\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 109, loss: 0.13227164559066296\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 110, loss: 0.13199905306100845\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 111, loss: 0.13172916695475578\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 112, loss: 0.13146196119487286\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 113, loss: 0.1311973687261343\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 114, loss: 0.13093536347150803\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 115, loss: 0.130675895139575\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 116, loss: 0.1304189246147871\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 117, loss: 0.13016440346837044\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 118, loss: 0.12991229817271233\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 119, loss: 0.12966256402432919\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 120, loss: 0.12941517122089863\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 121, loss: 0.12917007319629192\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 122, loss: 0.1289272177964449\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 123, loss: 0.12868660502135754\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 124, loss: 0.12844815663993359\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 125, loss: 0.12821188010275364\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 126, loss: 0.12797770649194717\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 127, loss: 0.1277456060051918\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 128, loss: 0.12751557491719723\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 129, loss: 0.12728753872215748\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 130, loss: 0.1270614955574274\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 131, loss: 0.12683740071952343\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 132, loss: 0.1266152262687683\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 133, loss: 0.12639494985342026\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 134, loss: 0.1261765267699957\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 135, loss: 0.12595993652939796\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 136, loss: 0.12574513629078865\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 137, loss: 0.12553211860358715\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 138, loss: 0.12532085366547108\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 139, loss: 0.1251113023608923\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 140, loss: 0.12490344606339931\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 141, loss: 0.1246972568333149\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 142, loss: 0.1244927030056715\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 143, loss: 0.12428977154195309\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 144, loss: 0.12408843450248241\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 145, loss: 0.12388866022229195\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 146, loss: 0.12369043938815594\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 147, loss: 0.1234937347471714\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 148, loss: 0.123298529535532\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 149, loss: 0.12310479953885078\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 150, loss: 0.12291251309216022\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 151, loss: 0.12272168323397636\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 152, loss: 0.12253224663436413\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 153, loss: 0.12234421446919441\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 154, loss: 0.12215753458440304\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 155, loss: 0.12197222001850605\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 156, loss: 0.12178822979331017\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 157, loss: 0.12160555459558964\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 158, loss: 0.12142417952418327\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 159, loss: 0.12124407105147839\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 160, loss: 0.12106521241366863\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 161, loss: 0.12088760174810886\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 162, loss: 0.12071120738983154\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 163, loss: 0.12053601630032063\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 164, loss: 0.12036201544106007\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 165, loss: 0.12018918618559837\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 166, loss: 0.12001750245690346\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 167, loss: 0.11984696052968502\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 168, loss: 0.11967754736542702\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 169, loss: 0.11950923502445221\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 170, loss: 0.11934201046824455\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 171, loss: 0.1191758718341589\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 172, loss: 0.119010791182518\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 173, loss: 0.11884675733745098\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 174, loss: 0.11868374794721603\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 175, loss: 0.11852177046239376\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 176, loss: 0.11836079694330692\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 177, loss: 0.11820081248879433\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 178, loss: 0.11804180592298508\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 179, loss: 0.11788377538323402\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 180, loss: 0.11772669106721878\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181, loss: 0.1175705436617136\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 182, loss: 0.11741533875465393\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 183, loss: 0.11726103723049164\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 184, loss: 0.11710764840245247\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 185, loss: 0.11695514991879463\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 186, loss: 0.11680353246629238\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 187, loss: 0.11665277928113937\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 188, loss: 0.11650289967656136\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 189, loss: 0.11635385453701019\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 190, loss: 0.11620566062629223\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 191, loss: 0.11605828069150448\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 192, loss: 0.11591172777116299\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 193, loss: 0.11576597765088081\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 194, loss: 0.11562102660536766\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 195, loss: 0.11547686345875263\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 196, loss: 0.11533347330987453\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 197, loss: 0.11519085057079792\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 198, loss: 0.11504898965358734\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 199, loss: 0.11490787751972675\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 200, loss: 0.11476750671863556\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 201, loss: 0.11462786607444286\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 202, loss: 0.11448895186185837\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 203, loss: 0.11435073986649513\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 204, loss: 0.11421323753893375\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 205, loss: 0.11407644115388393\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 206, loss: 0.11394032649695873\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 207, loss: 0.113804891705513\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 208, loss: 0.11367012932896614\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 209, loss: 0.1135360412299633\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 210, loss: 0.1134026013314724\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 211, loss: 0.11326981522142887\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 212, loss: 0.11313766613602638\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 213, loss: 0.11300615780055523\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 214, loss: 0.11287527531385422\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 215, loss: 0.1127450093626976\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 216, loss: 0.11261536367237568\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 217, loss: 0.11248631402850151\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 218, loss: 0.11235787160694599\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 219, loss: 0.11223001778125763\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 220, loss: 0.11210276745259762\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 221, loss: 0.11197607964277267\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 222, loss: 0.11184997670352459\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 223, loss: 0.11172443069517612\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 224, loss: 0.11159945651888847\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 225, loss: 0.1114750299602747\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 226, loss: 0.11135115474462509\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 227, loss: 0.11122781969606876\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 228, loss: 0.11110503412783146\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 229, loss: 0.11098277382552624\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 230, loss: 0.11086103692650795\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 231, loss: 0.1107398234307766\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 232, loss: 0.11061912775039673\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 233, loss: 0.11049893870949745\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 234, loss: 0.11037924885749817\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 235, loss: 0.11026007309556007\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 236, loss: 0.11014137603342533\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 237, loss: 0.11002317443490028\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 238, loss: 0.10990545153617859\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 239, loss: 0.10978821478784084\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 240, loss: 0.1096714548766613\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 241, loss: 0.10955515503883362\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 242, loss: 0.10943932831287384\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 243, loss: 0.10932395607233047\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 244, loss: 0.10920904390513897\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 245, loss: 0.10909458249807358\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 246, loss: 0.10898056626319885\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 247, loss: 0.10886699333786964\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 248, loss: 0.1087538581341505\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 249, loss: 0.10864116065204144\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 250, loss: 0.10852888599038124\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 251, loss: 0.10841703601181507\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 252, loss: 0.10830562189221382\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 253, loss: 0.10819460265338421\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 254, loss: 0.10808401741087437\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 255, loss: 0.10797383263707161\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 256, loss: 0.10786405391991138\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 257, loss: 0.1077546775341034\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 258, loss: 0.10764569416642189\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 259, loss: 0.10753711871802807\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 260, loss: 0.10742892324924469\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 261, loss: 0.1073211170732975\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 262, loss: 0.1072136927396059\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 263, loss: 0.1071066502481699\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 264, loss: 0.10699998028576374\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 265, loss: 0.10689368844032288\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 266, loss: 0.10678776167333126\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 267, loss: 0.10668220557272434\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 268, loss: 0.10657701082527637\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 269, loss: 0.10647217929363251\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 270, loss: 0.10636770352721214\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 271, loss: 0.10626358352601528\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 272, loss: 0.10615980625152588\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 273, loss: 0.10605638101696968\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 274, loss: 0.10595330223441124\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 275, loss: 0.10585056431591511\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 276, loss: 0.10574816167354584\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277, loss: 0.10564610175788403\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 278, loss: 0.10554436780512333\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 279, loss: 0.10544297099113464\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 280, loss: 0.10534189455211163\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 281, loss: 0.10524115152657032\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 282, loss: 0.10514072142541409\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 283, loss: 0.10504061728715897\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 284, loss: 0.10494082607328892\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 285, loss: 0.10484135523438454\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 286, loss: 0.10474218986928463\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 287, loss: 0.1046433299779892\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 288, loss: 0.10454478114843369\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 289, loss: 0.10444654151797295\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 290, loss: 0.10434859432280064\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 291, loss: 0.10425095446407795\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 292, loss: 0.1041536033153534\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 293, loss: 0.10405655018985271\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 294, loss: 0.10395978949964046\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 295, loss: 0.10386331751942635\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 296, loss: 0.10376713052392006\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 297, loss: 0.10367123037576675\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 298, loss: 0.10357561707496643\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 299, loss: 0.10348027758300304\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 300, loss: 0.10338522493839264\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 301, loss: 0.10329044237732887\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 302, loss: 0.10319593735039234\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 303, loss: 0.1031017154455185\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 304, loss: 0.1030077412724495\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 305, loss: 0.10291405580937862\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 306, loss: 0.1028206255286932\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 307, loss: 0.10272745974361897\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 308, loss: 0.10263456217944622\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 309, loss: 0.10254191979765892\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 310, loss: 0.10244953818619251\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 311, loss: 0.1023574136197567\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 312, loss: 0.10226554237306118\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 313, loss: 0.1021739300340414\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 314, loss: 0.10208256356418133\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 315, loss: 0.10199144668877125\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 316, loss: 0.10190057195723057\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 317, loss: 0.10180995613336563\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 318, loss: 0.10171957686543465\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 319, loss: 0.10162944160401821\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 320, loss: 0.10153954662382603\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 321, loss: 0.1014498844742775\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 322, loss: 0.10136046446859837\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 323, loss: 0.10127128288149834\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 324, loss: 0.10118233412504196\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 325, loss: 0.10109361447393894\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 326, loss: 0.10100513510406017\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 327, loss: 0.10091688111424446\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 328, loss: 0.10082884877920151\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 329, loss: 0.10074104554951191\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 330, loss: 0.10065347515046597\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 331, loss: 0.10056611709296703\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 332, loss: 0.10047898814082146\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 333, loss: 0.10039207525551319\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 334, loss: 0.10030538402497768\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 335, loss: 0.10021891258656979\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 336, loss: 0.10013265162706375\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 337, loss: 0.10004660859704018\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 338, loss: 0.09996078163385391\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 339, loss: 0.09987516701221466\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 340, loss: 0.09978975914418697\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 341, loss: 0.099704559892416\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 342, loss: 0.09961957111954689\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 343, loss: 0.09953479468822479\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 344, loss: 0.09945021569728851\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 345, loss: 0.0993658434599638\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 346, loss: 0.09928167425096035\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 347, loss: 0.09919770620763302\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 348, loss: 0.0991139393299818\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 349, loss: 0.09903037548065186\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 350, loss: 0.09894699975848198\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 351, loss: 0.09886383078992367\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 352, loss: 0.09878085739910603\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 353, loss: 0.0986980777233839\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 354, loss: 0.0986154843121767\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 355, loss: 0.09853308834135532\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 356, loss: 0.09845088422298431\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 357, loss: 0.09836886636912823\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 358, loss: 0.09828704036772251\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 359, loss: 0.09820540063083172\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 360, loss: 0.0981239527463913\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 361, loss: 0.0980426874011755\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 362, loss: 0.09796160086989403\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 363, loss: 0.09788070432841778\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 364, loss: 0.09779998287558556\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 365, loss: 0.09771945141255856\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 366, loss: 0.09763910621404648\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 367, loss: 0.09755893051624298\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 368, loss: 0.09747892990708351\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 369, loss: 0.09739911369979382\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 370, loss: 0.09731947630643845\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 371, loss: 0.09724000841379166\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 372, loss: 0.09716071747243404\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 373, loss: 0.09708160161972046\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 374, loss: 0.09700265526771545\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 375, loss: 0.09692388400435448\n",
      "Test_acc: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Epoch 376, loss: 0.09684528037905693\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 377, loss: 0.09676684252917767\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 378, loss: 0.09668858349323273\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 379, loss: 0.09661048837006092\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 380, loss: 0.09653256461024284\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 381, loss: 0.096454793587327\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 382, loss: 0.09637720324099064\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 383, loss: 0.0962997768074274\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 384, loss: 0.0962225142866373\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 385, loss: 0.09614540077745914\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 386, loss: 0.09606845676898956\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 387, loss: 0.09599168226122856\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 388, loss: 0.09591505862772465\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 389, loss: 0.09583860076963902\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 390, loss: 0.09576230309903622\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 391, loss: 0.09568614698946476\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 392, loss: 0.09561016783118248\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 393, loss: 0.09553433954715729\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 394, loss: 0.09545866213738918\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 395, loss: 0.09538314305245876\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 396, loss: 0.09530778229236603\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 397, loss: 0.09523257054388523\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 398, loss: 0.09515750966966152\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 399, loss: 0.0950825996696949\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 400, loss: 0.09500784799456596\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 401, loss: 0.09493324719369411\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 402, loss: 0.09485878981649876\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 403, loss: 0.09478448145091534\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 404, loss: 0.09471032209694386\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 405, loss: 0.09463631920516491\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 406, loss: 0.094562454149127\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 407, loss: 0.09448873996734619\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 408, loss: 0.09441517107188702\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 409, loss: 0.09434174187481403\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 410, loss: 0.09426846355199814\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 411, loss: 0.09419532120227814\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 412, loss: 0.09412232972681522\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 413, loss: 0.09404948353767395\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 414, loss: 0.09397676773369312\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 415, loss: 0.09390420280396938\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 416, loss: 0.09383177384734154\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 417, loss: 0.09375948831439018\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 418, loss: 0.09368733875453472\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 419, loss: 0.0936153270304203\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 420, loss: 0.09354345127940178\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 421, loss: 0.0934717245399952\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 422, loss: 0.09340012446045876\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 423, loss: 0.09332866407930851\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 424, loss: 0.09325733408331871\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 425, loss: 0.09318614937365055\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 426, loss: 0.09311509504914284\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 427, loss: 0.09304416552186012\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 428, loss: 0.09297338128089905\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 429, loss: 0.09290272183716297\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 430, loss: 0.09283220022916794\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 431, loss: 0.0927618034183979\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 432, loss: 0.09269154816865921\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 433, loss: 0.09262141026556492\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 434, loss: 0.09255141392350197\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 435, loss: 0.09248154237866402\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 436, loss: 0.09241180308163166\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 437, loss: 0.092342184856534\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 438, loss: 0.09227269887924194\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 439, loss: 0.09220334514975548\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 440, loss: 0.09213410876691341\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 441, loss: 0.09206500463187695\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 442, loss: 0.09199602343142033\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 443, loss: 0.0919271670281887\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 444, loss: 0.09185843914747238\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 445, loss: 0.09178983233869076\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 446, loss: 0.09172135964035988\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 447, loss: 0.09165300242602825\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 448, loss: 0.09158476628363132\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 449, loss: 0.0915166586637497\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 450, loss: 0.09144866466522217\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 451, loss: 0.09138079173862934\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 452, loss: 0.09131305105984211\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 453, loss: 0.09124541841447353\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 454, loss: 0.0911779124289751\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 455, loss: 0.09111053310334682\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 456, loss: 0.0910432618111372\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 457, loss: 0.09097611345350742\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 458, loss: 0.0909090843051672\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 459, loss: 0.09084217622876167\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 460, loss: 0.09077537804841995\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 461, loss: 0.09070869348943233\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 462, loss: 0.09064214117825031\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 463, loss: 0.09057569317519665\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 464, loss: 0.09050935879349709\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 465, loss: 0.09044314734637737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 466, loss: 0.09037705138325691\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 467, loss: 0.09031106904149055\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 468, loss: 0.09024519473314285\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 469, loss: 0.09017943777143955\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 470, loss: 0.09011379070580006\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 471, loss: 0.09004826284945011\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 472, loss: 0.08998285047709942\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 473, loss: 0.08991753309965134\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 474, loss: 0.0898523461073637\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 475, loss: 0.08978726156055927\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 476, loss: 0.0897222850471735\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 477, loss: 0.08965742588043213\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 478, loss: 0.08959267660975456\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 479, loss: 0.0895280372351408\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 480, loss: 0.0894635021686554\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 481, loss: 0.08939908258616924\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 482, loss: 0.08933476358652115\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 483, loss: 0.08927055820822716\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 484, loss: 0.08920645900070667\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 485, loss: 0.08914246782660484\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 486, loss: 0.08907858841121197\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 487, loss: 0.08901480585336685\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 488, loss: 0.08895114064216614\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 489, loss: 0.08888757228851318\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 490, loss: 0.08882412314414978\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 491, loss: 0.08876075968146324\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 492, loss: 0.0886975135654211\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 493, loss: 0.08863437362015247\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 494, loss: 0.08857133239507675\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 495, loss: 0.08850839175283909\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 496, loss: 0.08844556100666523\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 497, loss: 0.08838283643126488\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 498, loss: 0.08832021616399288\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 499, loss: 0.0882576871663332\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch): # 数据集级别的循环，每个epoch循环一次数据集\n",
    "    # 训练部分\n",
    "    for step,(x_train,y_train) in enumerate(train_db): # batch级别的循环 ，每个step循环一个batch\n",
    "        with tf.GradientTape(persistent=True) as g:        # with结构记录梯度信息\n",
    "            y = tf.matmul(x_train, w1) + b1 # 神经网络乘加运算\n",
    "            y = tf.nn.softmax(y) # 符合概率分布\n",
    "            y_ = tf.one_hot(y_train, depth=3 ) # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
    "            loss = tf.reduce_mean(tf.square(y-y_)) # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            loss_all += loss.numpy() # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
    "        # 计算loss对各个参数的梯度\n",
    "        grads = g.gradient(loss,[w1,b1])\n",
    "        \n",
    "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad\n",
    "        w1.assign_sub(LEARNING_RATE * grads[0]) # w1自动更新\n",
    "        b1.assign_sub(LEARNING_RATE * grads[1]) # b1自动更新\n",
    "        \n",
    "    # 每个epoch，打印loss信息\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all/4))\n",
    "    train_loss_results.append(loss_all/4)\n",
    "    loss_all = 0\n",
    "    \n",
    "    # 测试部分\n",
    "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
    "    total_correct = 0\n",
    "    total_number = 0\n",
    "    for x_test,y_test in test_db:\n",
    "        # 使用更新后的参数进行预测\n",
    "        y = tf.matmul(x_test,w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        predict = tf.argmax(y, axis=1) # 返回y中最大值的索引，即预测的分类\n",
    "        # 将pred转换为y_test的数据类型\n",
    "        predict = tf.cast(predict, dtype=y_test.dtype)\n",
    "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
    "        correct = tf.cast(tf.equal(predict,y_test), dtype=tf.int32)\n",
    "        # 将每个batch的correct数加起来\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        # 将所有batch中的correct数加起来\n",
    "        total_correct += correct\n",
    "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
    "        total_number += x_test.shape[0]\n",
    "    \n",
    "    # 总的准确率等于total_correct/total_number\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc.numpy())\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.one_hot() 函数将待转换数据转为one-hot形式输出； tf.one_hot(待转换数据，depth=分几类)\n",
    "- tf.nn.softmax() 使输出符合概率分布\n",
    "- assin_sub() 赋值操作， w.assign_sub(w要减去的值)\n",
    "- tf.argmax(tensor, axis=操作轴) 返回张量沿指定维度的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 loss 曲线\n",
    "plt.title('loss function curve') # picture title\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(train_loss_results, label='$Loss$') # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend() # 画出曲线图标\n",
    "plt.show()  # 画出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfZ0lEQVR4nO3dfZRcdZ3n8fcn3UkaQhBJwoN5oKMESRAJmIlBmFkGUINCcJZxBB+AXQZWF1h8XMHlgKKes+PsqOvIuoOO4LrypCgbMBIB8QEHIUFAkiAaMJAOIElIgE7oTrrqu3/cW51KpZtUd/p2ddfv8zqnT+reunXre5umPvX7/e7vXkUEZmaWrjGNLsDMzBrLQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwENmJJ+rmkTZLGN7qWokjaV9JXJT0tqVPSE/ny5EbXZulwENiIJKkd+EsggEXD/N6tw/Q+44C7gSOAhcC+wLHARmD+IPY3LHVb83EQ2Eh1NvAb4DrgnOonJE2X9ENJ6yVtlPT1qufOl/SYpJclrZJ0TL4+JB1atd11kr6QPz5BUoekT0t6DrhW0msl3Z6/x6b88bSq1+8v6VpJz+TP35qvXyHptKrtxkraIOnofo5xBvA3EbEqIsoR8XxEfD4ilgyy7scknVq1fWt+DJXfwwJJ/yZps6RHJJ0wsP8s1owcBDZSnQ18L/95p6QDASS1ALcDTwHtwFTgxvy59wKfzV+7L1lLYmOd73cQsD9wCHAB2f8b1+bLM4BXgK9Xbf9dYG+yb/MHAF/J1/8f4INV270LeDYiHurjPU8G7oiIzjprrKfuG4Czqp5/J7AhIn4raSrwY+AL+Ws+CdwiacoevL81AQeBjTiSjif7YLs5Ih4EngDenz89H3gd8KmI2BIRXRFxb/7c3wNfiohlkVkdEU/V+bZl4MqI6I6IVyJiY0TcEhFbI+Jl4IvAv8vrOxg4BfhwRGyKiO0R8Yt8P/8XeJekffPlD5GFRl8mAc/WWV9ddQPXA4sk7Z0//36ycIAsoJZExJK89XEnsJwsrCxhDgIbic4BfhoRG/Ll69nRPTQdeCoievp43XSy0BiM9RHRVVmQtLekf5H0lKSXgF8C++UtkunACxGxqXYnEfEM8GvgDEn7kQXG9/p5z43AwYOst8+6I2I18BhwWh4Gi8h+f5CF63vzbqHNkjYDxw9BDTbKeXDJRhRJewF/B7Tk/d4A48k+hI8C1gIzJLX2EQZrgTf0s+utZF05FQcBHVXLtZfh/QTwRuCtEfGcpLnAQ4Dy99lf0n4RsbmP9/oOWeukFbgvItb1U9NdwBckTYiILUNUN+zoHhoDrMrDgbzu70bE+f28lyXKLQIbad4DlIA5wNz8ZzbwK7K+/wfIulP+u6QJktokHZe/9lvAJyW9RZlDJR2SP/cw8H5JLZIWknfzvIqJZOMCmyXtD1xZeSIingV+AvyvfFB5rKS/qnrtrcAxwCVkYwb9+S7Zh/Mtkg6XNEbSJEmfkVTprhlo3ZCNmbwD+Ag7WgOQdVudJumd+f7a8gHnaX3uxZLhILCR5hzg2oh4OiKeq/yQDdR+gOwb+WnAocDTZN+O3wcQEd8n68u/HniZ7AN5/3y/l+Sv25zv59bd1PFVYC9gA9nZS3fUPP8hYDvwe+B54KOVJ/K++luAmcAP+3uDiOgmGzD+PXAn8BJZ0E0G7h9k3ZWgug94G3BT1fq1wOnAZ4D1ZCH0Kfw5kDz5xjRmQ0/SFcBhEfHB3W5s1mAeIzAbYnlX0nlkrQazEc9NQrMhJOl8si6Xn0TELxtdj1k93DVkZpY4twjMzBI36sYIJk+eHO3t7Y0uw8xsVHnwwQc3RESflxMZdUHQ3t7O8uXLG12GmdmoIqnfy624a8jMLHEOAjOzxDkIzMwSN+rGCPqyfft2Ojo66Orq2v3Go0xbWxvTpk1j7NixjS7FzJpUUwRBR0cHEydOpL29HUmNLmfIRAQbN26ko6ODmTNnNrocM2tSTdE11NXVxaRJk5oqBAAkMWnSpKZs6ZjZyNEUQQA0XQhUNOtxmdnI0RRdQ2Y2fH7wYAdPb+zvPjpWpJNmH8hR0/cb8v06CMysbq9sK/HJ7z8CgBurw++AfdscBGbWWC93bwfg8+95Ex9acMhutrbRomnGCEaSiy++mEMO8f8k1nw6u7LbRE8c7++QzcRBMMTWrFnDPffcw7Zt23j55ZcbXY7ZkNrSXQJggoOgqTgIhtiVV17J5Zdfzpw5c1i5cmXv+meeeYYzzjiDo48+msMPP5wHHnigz3VmI1mla2jC+JYGV2JDqeli/XO3rWTVMy8N6T7nvG5frjztiN1ut3LlSlasWMF1113Hvffey4oVK1iwYAE9PT2ccsopfPGLX+TUU09l69atlEoljj/++F3WmY1klRbBxPGe6d5M3CIYQpdffjlXXXUVkpg9e3Zvi+DWW29l9uzZnHrqqQDsvffeLF26dJd1EydObFjtZvXodIugKTVdi6Ceb+5FuP/++7njjjt46KGHuPDCC+nq6uLII48E4OGHH2bBggU7bd/XOrORrjNvEezT1nQfHUlzi2CIfOYzn+G2225jzZo1rFmzhkceeaS3RXDQQQftNF6wfv36PteZjXRburOzhvbxYHFTKTQIJC2U9Lik1ZIu7eP5GZLukfSQpN9JeleR9RTlrrvuYtu2bZx88sm96w488EA6Ozt54YUXOPfcc/nzn//MEUccwdy5c7nvvvv6XGc20nV29TBGsNdYdw01k8JiXVILcDXwdqADWCZpcUSsqtrscuDmiPiGpDnAEqC9qJqKcvLJJ+8UAhUvvbRj0Hrx4sW7PN/XOrORrLO7hwnjW30NrCZTZPtuPrA6Ip4EkHQjcDpQHQQB7Js/fg3wTIH1mFnu2l//iW/96k8Dft2mrdvYby+fMdRsigyCqcDaquUO4K0123wW+Kmki4EJwK5fqwFJFwAXAMyYMWPICzVLza/+uIGt23o4afaBA37t/Jn7F1CRNVKjR3zOAq6LiH+SdCzwXUlviohy9UYRcQ1wDcC8efOirx1FRFM2VyP6PFyzPdLZ3cNhB07kf7z3qEaXYiNAkYPF64DpVcvT8nXVzgNuBoiI+4A2YPJA36itrY2NGzc23Ydm5Q5lbW1tjS7FmsyW7h6f+WO9ivxLWAbMkjSTLADOBN5fs83TwEnAdZJmkwXBgM+jnDZtGh0dHU15CmblnsVmQ6mzu8dzAaxXYX8JEdEj6SJgKdACfDsiVkq6ClgeEYuBTwDflPQxsoHjc2MQX+vHjh3re/qaDcCW/OwfMyh4jCAilpCdElq97oqqx6uA44qswcx29XKXu4ZsB88sNktMT6lMd0/ZQWC9HARmifE9BayWg8AsMZV7CvguY1bhIDBLjFsEVst/CWajyNoXttKx6ZU92sfq57NbqPqeAlbhIDAbRRZ9/V42bd0+JPuaMnH8kOzHRj8Hgdkosb1UZtPW7bxv3nTec/TUPdrXxLZW5hy87+43tCQ4CMxGicpNYd540ESOfcOkBldjzcSDxWajxMtd+d3BfGkIG2IOArNRYss23ybSiuEgMBslOvMWgU/7tKHmIDAbJTp943griIPAbJRwEFhRHARmo0TlrCEPFttQcxCYjRKd+aUh9hnnILCh5SAwGyV2DBb70hA2tPzVwqxAq5/v5Ju/fJLSENxPe8W6F2kbO4bWFn9/s6HlIDAr0OJHnuGm5WuZut9eQ7K/k2cfOCT7MavmIDArUGdXDxPGtfDrS09sdClm/XIb06xAW7p7fJaPjXgOArMCdW7r8UxgG/EcBGYF6uzq8S0hbcRzEJgVaEu3WwQ28jkIzArU6SCwUcBBYFagzm53DdnI5yAwK5C7hmw0KDQIJC2U9Lik1ZIu7eP5r0h6OP/5g6TNRdZjNtw6ffqojQKF/YVKagGuBt4OdADLJC2OiFWVbSLiY1XbXwwcXVQ9ZsOtu6fE9lL4stE24hX5FzofWB0RTwJIuhE4HVjVz/ZnAVcWWI8l7rIfPsoNDzw97O870S0CG+GK/AudCqytWu4A3trXhpIOAWYCP+vn+QuACwBmzJgxtFVaMh5dt5nXT57AqUe9btjec+wY8e4jDx629zMbjJHyVeVM4AcRUerryYi4BrgGYN68eXt+GUdLUmdXD2+eth8ff/thjS7FbEQpcrB4HTC9anlavq4vZwI3FFiLGZ3dJZ/BY9aHIoNgGTBL0kxJ48g+7BfXbiTpcOC1wH0F1mKWXQDON3Ux20VhQRARPcBFwFLgMeDmiFgp6SpJi6o2PRO4MWII7txh1o+eUplXtpfYZ/zYRpdiNuIU2k6OiCXAkpp1V9Qsf7bIGswAtmzLhp98m0ezXXlmsSWhszu736/P6TfblYPAkrClEgQ+p99sFw4CS0KlReCzhsx25SCwJHR2uWvIrD/J/1/x4FMvsGbD1kaXYQV7dN2LgIPArC/J/19x9r8+0HtGiTW3sS3igInjG12G2YiTdBBEBFu2lTj3be38x+NmNrocK9jEtlZeO2Fco8swG3GSDoJtpTIAUyaOZ8akvRtcjZlZYyQ9WLytJwuCcS1J/xrMLHFJfwL2BkFr0r8GM0tc0p+A20vZ5Y3GukVgZglL+hPQLQIzs9SDoJSdNuogMLOUJf0JuK0n6xryYLGZpSzpT8DK6aPjWtXgSszMGiftIOg9fdTXqDezdDkI8BiBmaUt6U/A7XnX0NgWdw2ZWbqSDoJutwjMzNIOgspg8XgHgZklLOlPwO09la6hpH8NZpa4pD8Bd5w+mvSvwcwSl/QnoK8+amaWeBBsd4vAzCztIOj2GIGZWbFBIGmhpMclrZZ0aT/b/J2kVZJWSrq+yHpquWvIzKyOW1VKOg34cUSUB7JjSS3A1cDbgQ5gmaTFEbGqaptZwGXAcRGxSdIBA6p+D20rlRnbIsaM8YQyM0tXPV+F3wf8UdKXJB0+gH3PB1ZHxJMRsQ24ETi9ZpvzgasjYhNARDw/gP3vse09ZXcLmVnydvspGBEfBI4GngCuk3SfpAskTdzNS6cCa6uWO/J11Q4DDpP0a0m/kbRwALXvsaxF4CAws7TV9SkYES8BPyD7Vn8w8DfAbyVdvIfv3wrMAk4AzgK+KWm/2o3y4Fkuafn69ev38C13KJWDVncLmVnidhsEkhZJ+hHwc2AsMD8iTgGOAj7xKi9dB0yvWp6Wr6vWASyOiO0R8SfgD2TBsJOIuCYi5kXEvClTpuyu5LqVIzw+YGbJq6dFcAbwlYg4MiL+sdKPHxFbgfNe5XXLgFmSZkoaB5wJLK7Z5lay1gCSJpN1FT05sEMYvFI5aJGDwMzSVk8QfBZ4oLIgaS9J7QARcXd/L4qIHuAiYCnwGHBzRKyUdJWkRflmS4GNklYB9wCfioiNgziOQSkHuEFgZqnb7emjwPeBt1Utl/J1f7G7F0bEEmBJzborqh4H8PH8Z9iVy+4aMjOrp0XQmp/+CUD+eFxxJQ2fUgQtDgIzS1w9QbC+qisHSacDG4orafiUA48RmFny6uka+jDwPUlfB0Q2N+DsQqsaJuVy4Bwws9TtNggi4glggaR98uXOwqsaJqWyu4bMzOppESDp3cARQJvyr9ARcVWBdQ2LcgRj3CQws8TVM6Hsf5Ndb+hisq6h9wKHFFxXIR586gWeWL+jQeMgMDOrb7D4bRFxNrApIj4HHEs28WvUOeMb93HSP/2id9ldQ2Zm9QVBV/7vVkmvA7aTXW9o1CsHnkdgZsmrZ4zgtvxCcP8I/BYI4JuFVjVMsq6hRldhZtZYrxoEksYAd0fEZuAWSbcDbRHx4rBUVzBfa8jMbDddQ/ldya6uWu5ulhAAX33UzAzqGyO4W9IZUvN9dS6XfdE5M7N6guA/kV1krlvSS5JelvRSwXUNC19ryMysvpnFu7sl5ajleQRmZnUEgaS/6mt9RPxy6MsZXuWyg8DMrJ7TRz9V9bgNmA88CJxYSEXDyF1DZmb1dQ2dVr0saTrw1cIqGkalMm4RmFny6hksrtUBzB7qQhohPKHMzKyuMYJ/JptNDFlwzCWbYTzq+VpDZmb1jREsr3rcA9wQEb8uqJ5hVfKEMjOzuoLgB0BXRJQAJLVI2jsithZbWvHCt6o0M6tvZjGwV9XyXsBdxZQzvEpljxGYmdUTBG3Vt6fMH+9dXEnDp1R215CZWT1BsEXSMZUFSW8BXimupOET4auPmpnVM0bwUeD7kp4hu1XlQWS3rhz1Sr7EhJlZXRPKlkk6HHhjvurxiNhebFnDo1T2HcrMzOq5ef2FwISIWBERK4B9JP3nenYuaaGkxyWtlnRpH8+fK2m9pIfzn78f+CHUJyL6XNcymCl1ZmZNpJ6PwfPzO5QBEBGbgPN39yJJLWQ3tTkFmAOcJWlOH5veFBFz859v1Vn3gPWRA+4aMjOjviBoqb4pTf4BP66O180HVkfEkxGxDbgROH1wZe65ch9JUPLVR83M6gqCO4CbJJ0k6STgBuAndbxuKrC2arkjX1frDEm/k/SD/IJ2hSj30SKIwJeYMLPk1RMEnwZ+Bnw4/3mUnSeY7YnbgPaIeDNwJ/CdvjaSdIGk5ZKWr1+/flBv1H+LYFC7MzNrGrsNgvwG9vcDa8i6e04EHqtj3+uA6m/40/J11fveGBHd+eK3gLf0U8M1ETEvIuZNmTKljrfuax+7rvO1hszMXuX0UUmHAWflPxuAmwAi4q/r3PcyYJakmWQBcCbw/pr3ODgins0XF1FfwAxKXy0CTygzM3v1eQS/B34FnBoRqwEkfazeHUdEj6SLgKVAC/DtiFgp6SpgeUQsBv6LpEVkVzV9ATh3cIexex4sNjPr26sFwb8n+xZ/j6Q7yM76GdCnZkQsAZbUrLui6vFlwGUD2edg1Q4WRwTl8IQyM7N+xwgi4taIOBM4HLiH7FITB0j6hqR3DFeBQ6YmCCrB4K4hM0tdPYPFWyLi+vzexdOAh8jOJBpVaruGKstuEJhZ6gZ0gYWI2JSfwXNSUQUVpTYISnmTwF1DZpa6ZK60UztGUAkGTygzs9QlEwS1F52rBINzwMxSl0wQ1LYIeruGPFhsZolLKAhqWgRldw2ZmUHKQeAxAjMzIKEgqJ1YXMpXyF1DZpa4ZIJg166h7F9PKDOz1CUUBLXLla6hBhRjZjaCJPMxWHv6aOWsIXcNmVnqkgmCflsEDgIzS1wyQdDfhDKfNWRmqUsmCPqbUOYGgZmlLqEg8DwCM7O+OAjcJDCzxCUTBLtMKPNZQ2ZmQEJB0O+EMncNmVniEgqC2mVPKDMzg6SCoGZCma81ZGYGJBQEu8wjKHuw2MwMkgqCnZdLvh+BmRmQUBDsOkaQ/esGgZmlLqEg2JEEEeF5BGZmuUSDwF1DZmYVhQaBpIWSHpe0WtKlr7LdGZJC0ryiaqkeIwh2BMMYB4GZJa6wIJDUAlwNnALMAc6SNKeP7SYClwD3F1UL7NwiKFd1DY1x15CZJa7IFsF8YHVEPBkR24AbgdP72O7zwD8AXQXWstNgcTmCkm9VaWYGFBsEU4G1Vcsd+bpeko4BpkfEj19tR5IukLRc0vL169cPqpjaMYIdXUOD2p2ZWdNo2MegpDHAl4FP7G7biLgmIuZFxLwpU6YM6v2iNgjK7hoyM4Nig2AdML1qeVq+rmIi8Cbg55LWAAuAxUUNGFcuMgd515DvR2BmBhQbBMuAWZJmShoHnAksrjwZES9GxOSIaI+IduA3wKKIWF5EMTt1DbFjzMAtAjNLXWFBEBE9wEXAUuAx4OaIWCnpKkmLinrffuupelyOqOoaGu5KzMxGltYidx4RS4AlNeuu6GfbEwquZcfjsieUmZlVJHPOTHmnCWWeR2BmVpFQEFRPKPPMYjOzioSCoPqxJ5SZmVUkEwS7zCPwhDIzMyChIOjvMtQeIzCz1KUTBDtNKKs6a8hBYGaJSycIdppQFr1B4MFiM0tdMkEQOw0W71h2DphZ6pIJgp1OHy37WkNmZhUJBcGOx9W3qvRgsZmlLpkgCHYeIwi3CMzMgISCoFwzRlCZUOYWgZmlLpkgiJp7FpfCVx81M4OEgqBc3nlmcUQwRiC3CMwscekEwU6Dxdk8AncLmZklFQQ7X320FOHJZGZmJBQE1RPKsrOGfHkJMzNIKAh2nlBG3jXUwILMzEaIZILg+FmT+ctZk4HK/QjcNWRmBgkFwRGvew1nH9veuxwRnkxmZkZCQQA75gxU5hH4rCEzs8SCQL1BkM0sdhCYmSUXBNkHf0TkXUMNLsjMbARI6qOw0gKo3KHMLQIzs8SCoPKxHx4jMDPrlVQQVD74g2yCmc8aMjMrOAgkLZT0uKTVki7t4/kPS3pU0sOS7pU0p8h6es8aKocnlJmZ5QoLAkktwNXAKcAc4Kw+Puivj4gjI2Iu8CXgy0XVkxWV/eNrDZmZ7VBki2A+sDoinoyIbcCNwOnVG0TES1WLE6DqNmIF2NE1FJTL4WsNmZkBrQXueyqwtmq5A3hr7UaSLgQ+DowDTuxrR5IuAC4AmDFjxqALas1bANtLQdmDxWZmwAgYLI6IqyPiDcCngcv72eaaiJgXEfOmTJky6PeaMD7Lva3dPdmEMncNmZkVGgTrgOlVy9Pydf25EXhPgfWwTx4EL3f3UPaEMjMzoNggWAbMkjRT0jjgTGBx9QaSZlUtvhv4Y4H19AbBlkoQuGvIzKy4MYKI6JF0EbAUaAG+HRErJV0FLI+IxcBFkk4GtgObgHOKqgd2dA11dvVQKofvV2xmRrGDxUTEEmBJzborqh5fUuT71xrXOoZxrWPo3FbpGnIQmJkl10s+cXwrnV09lMu+VaWZGSQYBBPGt7Klu4dSBM4BM7MEg2Cf8a10dvdkE8rcNWRmlnAQeIzAzAxIMQjasiAoBT5ryMyMBINgwvhW/vBcJ79/9iVanANmZsWePjoSnfkX0ymVywC8Z+7UBldjZtZ4yQXBcYdO5rhDJze6DDOzESO5riEzM9uZg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwSp4hodA0DImk98NQgXz4Z2DCE5YwGPuY0+JjTsCfHfEhETOnriVEXBHtC0vKImNfoOoaTjzkNPuY0FHXM7hoyM0ucg8DMLHGpBcE1jS6gAXzMafAxp6GQY05qjMDMzHaVWovAzMxqOAjMzBKXTBBIWijpcUmrJV3a6HqGiqRvS3pe0oqqdftLulPSH/N/X5uvl6Sv5b+D30k6pnGVD56k6ZLukbRK0kpJl+Trm/a4JbVJekDSI/kxfy5fP1PS/fmx3SRpXL5+fL68On++vZH1D5akFkkPSbo9X27q4wWQtEbSo5IelrQ8X1fo33YSQSCpBbgaOAWYA5wlaU5jqxoy1wELa9ZdCtwdEbOAu/NlyI5/Vv5zAfCNYapxqPUAn4iIOcAC4ML8v2czH3c3cGJEHAXMBRZKWgD8A/CViDgU2AScl29/HrApX/+VfLvR6BLgsarlZj/eir+OiLlVcwaK/duOiKb/AY4FllYtXwZc1ui6hvD42oEVVcuPAwfnjw8GHs8f/wtwVl/bjeYf4P8Bb0/luIG9gd8CbyWbZdqar+/9OweWAsfmj1vz7dTo2gd4nNPyD70TgdsBNfPxVh33GmByzbpC/7aTaBEAU4G1Vcsd+bpmdWBEPJs/fg44MH/cdL+HvAvgaOB+mvy4826Sh4HngTuBJ4DNEdGTb1J9XL3HnD//IjBpeCveY18F/itQzpcn0dzHWxHATyU9KOmCfF2hf9vJ3bw+NRERkpryHGFJ+wC3AB+NiJck9T7XjMcdESVgrqT9gB8Bhze4pMJIOhV4PiIelHRCo+sZZsdHxDpJBwB3Svp99ZNF/G2n0iJYB0yvWp6Wr2tWf5Z0MED+7/P5+qb5PUgaSxYC34uIH+arm/64ASJiM3APWdfIfpIqX+iqj6v3mPPnXwNsHOZS98RxwCJJa4AbybqH/ifNe7y9ImJd/u/zZIE/n4L/tlMJgmXArPyMg3HAmcDiBtdUpMXAOfnjc8j60Cvrz87PNFgAvFjV3Bw1lH31/1fgsYj4ctVTTXvckqbkLQEk7UU2JvIYWSD8bb5Z7TFXfhd/C/ws8k7k0SAiLouIaRHRTvb/688i4gM06fFWSJogaWLlMfAOYAVF/203emBkGAdg3gX8gaxf9b81up4hPK4bgGeB7WT9g+eR9Y3eDfwRuAvYP99WZGdPPQE8CsxrdP2DPObjyfpRfwc8nP+8q5mPG3gz8FB+zCuAK/L1rwceAFYD3wfG5+vb8uXV+fOvb/Qx7MGxnwDcnsLx5sf3SP6zsvJZVfTfti8xYWaWuFS6hszMrB8OAjOzxDkIzMwS5yAwM0ucg8DMLHEOArMakkr5lR8rP0N2tVpJ7aq6UqzZSOBLTJjt6pWImNvoIsyGi1sEZnXKrxP/pfxa8Q9IOjRf3y7pZ/n14O+WNCNff6CkH+X3EHhE0tvyXbVI+mZ+X4Gf5jOFzRrGQWC2q71quobeV/XcixFxJPB1sqtjAvwz8J2IeDPwPeBr+fqvAb+I7B4Cx5DNFIXs2vFXR8QRwGbgjIKPx+xVeWaxWQ1JnRGxTx/r15DdHObJ/KJ3z0XEJEkbyK4Bvz1f/2xETJa0HpgWEd1V+2gH7ozsBiNI+jQwNiK+UPyRmfXNLQKzgYl+Hg9Ed9XjEh6rswZzEJgNzPuq/r0vf/xvZFfIBPgA8Kv88d3AR6D3pjKvGa4izQbC30TMdrVXfiewijsionIK6Wsl/Y7sW/1Z+bqLgWslfQpYD/yHfP0lwDWSziP75v8RsivFmo0oHiMwq1M+RjAvIjY0uhazoeSuITOzxLlFYGaWOLcIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS9/8Bje3GNRJFri4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 accuracy 曲线\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(test_acc, label='$ Acc $') # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4],\n",
       "       [5, 4, 3],\n",
       "       [8, 7, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1,2,3],[2,3,4],[5,4,3],[8,7,2]])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([3, 3, 1])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(test,axis=0) #  竖着"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([2, 2, 0, 0])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(test,axis=1) # 横着"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.1",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
