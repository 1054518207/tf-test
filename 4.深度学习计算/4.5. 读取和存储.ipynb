{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. 读取和存储\n",
    "到目前为止，我们介绍了如何处理数据以及如何构建、训练和测试深度学习模型。然而在实际中，我们有时需要把训练好的模型部署到很多不同的设备。在这种情况下，我们可以把内存中训练好的模型参数存储在硬盘上供后续读取使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1. 读写`Tensor`\n",
    "\n",
    "我们可以直接使用`save`函数和`load`函数分别存储和读取。下面的例子创建了tensor`x`，并将其存在文件名同为x的文件里。Tensorflow暂时没有保存和读取矩阵数据，只能保存和读取模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones(3)\n",
    "np.save('x.npy',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们将数据从存储的文件读回内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.load('x.npy')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以存储一列`tensor`并读回内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.ones(4)\n",
    "np.save('xy.npy',[x,y])\n",
    "x2,y2 = np.load('xy.npy',allow_pickle=True)\n",
    "(x2,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们甚至可以存储并读取一个从字符串映射到`tensor`的字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'x': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>, 'y': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x':x,'y':y}\n",
    "np.save('mydict.npy',mydict)\n",
    "mydict2 = np.load('mydict.npy',allow_pickle=True)\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2. 读写Keras模型的参数\n",
    "`Keras`的`Model`类提供了`get_weights()`函数和`save_weights`函数来读写模型参数。为了演示方便，我们先创建一个多层感知机，并将其初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 20), dtype=float32, numpy=\n",
       " array([[0.72066367, 0.74439263, 0.8329483 , 0.877746  , 0.7424873 ,\n",
       "         0.70886314, 0.40852106, 0.46363497, 0.8317559 , 0.612955  ,\n",
       "         0.7960923 , 0.12308407, 0.24153852, 0.5242946 , 0.9429413 ,\n",
       "         0.1000005 , 0.27063715, 0.6172676 , 0.20213592, 0.8636596 ],\n",
       "        [0.4910003 , 0.5663651 , 0.36159134, 0.73424375, 0.76822996,\n",
       "         0.81424034, 0.9148189 , 0.23447478, 0.9114976 , 0.10812128,\n",
       "         0.2592802 , 0.91107   , 0.3662306 , 0.31527257, 0.12566042,\n",
       "         0.17648566, 0.16609132, 0.7959317 , 0.26270187, 0.10316133]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       " array([[ 0.12259766, -0.16459455, -0.22024137, -0.29355842,  0.06675099,\n",
       "         -0.28008884, -0.20612115, -0.0884061 , -0.43741766,  0.21470258],\n",
       "        [-0.06200828, -0.20888153, -0.21636906, -0.2486872 , -0.10419051,\n",
       "         -0.06668977, -0.07280136, -0.234931  , -0.21029462, -0.1390564 ]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "class MLP(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.hidden = keras.layers.Dense(256, activation='relu')\n",
    "        self.outputs = keras.layers.Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        inputs = self.flatten(x)\n",
    "        hid = self.hidden(inputs)\n",
    "        out = self.outputs(hid)\n",
    "        return out\n",
    "\n",
    "net = MLP()\n",
    "X = tf.random.uniform(shape=(2, 20))\n",
    "Y = net(X)\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面把该模型的参数存成文件，文件名为`mlp_params.h5`。[参考官方文档](https://tensorflow.google.cn/guide/keras/save_and_serialize#part_ii_saving_and_loading_of_subclassed_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mlp_params.h5'\n",
    "net.save_weights(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们再实例化一次定义好的多层感知机。与随机初始化模型参数不同，我们在这里直接读取保存在文件里的参数。\n",
    "\n",
    "因为这两个实例都有同样的模型参数，那么对同一个输入X的计算结果将会是一样的。我们来验证一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = MLP()\n",
    "net2(X)\n",
    "net2.load_weights(filename)\n",
    "Y2 = net2(X)\n",
    "Y2 == Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.1",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
