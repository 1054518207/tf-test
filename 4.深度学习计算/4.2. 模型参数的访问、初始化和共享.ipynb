{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. 模型参数的访问、初始化和共享\n",
    "在“线性回归的简洁实现”一节中，我们通过`init`模块来初始化模型的全部参数。我们也介绍了访问模型参数的简单方法。本节将深入讲解如何访问和初始化模型参数，以及如何在多个层之间共享同一份模型参数。\n",
    "\n",
    "我们先定义一个与上一节中相同的含单隐藏层的多层感知机。我们依然使用默认方式初始化它的参数，并做一次前向计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.11525244, -0.13519563,  0.20563626,  0.1947599 , -0.06194043,\n",
       "        -0.22070742,  0.18779312,  0.1698063 ,  0.12842052, -0.18753651],\n",
       "       [ 0.3472902 , -0.18563515,  0.3329596 ,  0.12333538, -0.23827925,\n",
       "        -0.10464031,  0.16165382,  0.4064858 ,  0.06976099, -0.11919112]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = keras.Sequential()\n",
    "net.add(keras.layers.Flatten())\n",
    "net.add(keras.layers.Dense(256, activation='relu'))\n",
    "net.add(keras.layers.Dense(10))\n",
    "\n",
    "X = tf.random.uniform(shape=(2, 20))\n",
    "Y = net(X)  # 前向计算\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. 访问模型参数\n",
    "对于使用`Sequential`类构造的神经网络，我们可以通过`weights`属性来访问网络任一层的权重。回忆一下上一节中提到的`Sequential`类与`tf.keras.Model`类的继承关系。对于`Sequential`实例中含模型参数的层，我们可以通过`tf.keras.Model`类的`weights`属性来访问该层包含的所有参数。下面，访问多层感知机`net`中隐藏层的所有参数。索引`0`表示隐藏层为`Sequential`实例最先添加的层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'sequential/dense/kernel:0' shape=(20, 256) dtype=float32, numpy=\n",
       " array([[-0.07069016,  0.11090916, -0.13917884, ...,  0.05293907,\n",
       "         -0.09434916,  0.08805928],\n",
       "        [-0.1346477 ,  0.10465711, -0.02740826, ..., -0.04868089,\n",
       "         -0.09580112,  0.11522248],\n",
       "        [-0.03858206,  0.06133232,  0.09340487, ...,  0.12659445,\n",
       "         -0.07707801, -0.1015819 ],\n",
       "        ...,\n",
       "        [ 0.10917932,  0.1103344 ,  0.03767487, ...,  0.10450956,\n",
       "          0.08945026,  0.02449542],\n",
       "        [ 0.0456754 ,  0.0581727 ,  0.0269246 , ...,  0.09464845,\n",
       "         -0.11656308, -0.09958023],\n",
       "        [ 0.04684894, -0.00157274, -0.03242975, ...,  0.1232672 ,\n",
       "         -0.1369152 ,  0.0503927 ]], dtype=float32)>,\n",
       " tensorflow.python.ops.resource_variable_ops.ResourceVariable)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights[0],type(net.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sequential/dense/kernel:0' shape=(20, 256) dtype=float32, numpy=\n",
       " array([[-0.07069016,  0.11090916, -0.13917884, ...,  0.05293907,\n",
       "         -0.09434916,  0.08805928],\n",
       "        [-0.1346477 ,  0.10465711, -0.02740826, ..., -0.04868089,\n",
       "         -0.09580112,  0.11522248],\n",
       "        [-0.03858206,  0.06133232,  0.09340487, ...,  0.12659445,\n",
       "         -0.07707801, -0.1015819 ],\n",
       "        ...,\n",
       "        [ 0.10917932,  0.1103344 ,  0.03767487, ...,  0.10450956,\n",
       "          0.08945026,  0.02449542],\n",
       "        [ 0.0456754 ,  0.0581727 ,  0.0269246 , ...,  0.09464845,\n",
       "         -0.11656308, -0.09958023],\n",
       "        [ 0.04684894, -0.00157274, -0.03242975, ...,  0.1232672 ,\n",
       "         -0.1369152 ,  0.0503927 ]], dtype=float32)>,\n",
       " <tf.Variable 'sequential/dense/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32)>,\n",
       " <tf.Variable 'sequential/dense_1/kernel:0' shape=(256, 10) dtype=float32, numpy=\n",
       " array([[-0.02896862,  0.11204925, -0.09403903, ...,  0.05314542,\n",
       "          0.12320822,  0.11887109],\n",
       "        [ 0.05644652, -0.09880087,  0.14737949, ...,  0.02895984,\n",
       "          0.083308  , -0.02785765],\n",
       "        [ 0.13273332,  0.10587853,  0.02558748, ..., -0.08806142,\n",
       "         -0.04829325, -0.14270385],\n",
       "        ...,\n",
       "        [-0.0609996 ,  0.02895719,  0.14596304, ...,  0.11210126,\n",
       "          0.08845362,  0.00260761],\n",
       "        [ 0.01745588, -0.03792968, -0.03807244, ...,  0.07506689,\n",
       "          0.07314721, -0.0948716 ],\n",
       "        [-0.10724197,  0.08598734,  0.05092184, ..., -0.01826824,\n",
       "         -0.11841708,  0.12178284]], dtype=float32)>,\n",
       " <tf.Variable 'sequential/dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.07069016,  0.11090916, -0.13917884, ...,  0.05293907,\n",
       "         -0.09434916,  0.08805928],\n",
       "        [-0.1346477 ,  0.10465711, -0.02740826, ..., -0.04868089,\n",
       "         -0.09580112,  0.11522248],\n",
       "        [-0.03858206,  0.06133232,  0.09340487, ...,  0.12659445,\n",
       "         -0.07707801, -0.1015819 ],\n",
       "        ...,\n",
       "        [ 0.10917932,  0.1103344 ,  0.03767487, ...,  0.10450956,\n",
       "          0.08945026,  0.02449542],\n",
       "        [ 0.0456754 ,  0.0581727 ,  0.0269246 , ...,  0.09464845,\n",
       "         -0.11656308, -0.09958023],\n",
       "        [ 0.04684894, -0.00157274, -0.03242975, ...,  0.1232672 ,\n",
       "         -0.1369152 ,  0.0503927 ]], dtype=float32),\n",
       " (20, 256))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights[0].numpy(),net.weights[0].numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. 初始化模型参数\n",
    "我们在\\[“数值稳定性和模型初始化”\\]一节中描述了模型的默认初始化方法：权重参数元素为\\[-0.07, 0.07\\]之间均匀分布的随机数，偏差参数则全为0。但我们经常需要使用其他方法来初始化权重。在下面的例子中，我们将权重参数初始化成均值为0、标准差为0.01的正态分布随机数，并依然将偏差参数清零。(暂时不知道`keras`有重新初始化参数的方式)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00057808,  0.01212484,  0.02041551, ...,  0.00143753,\n",
       "         -0.01051395,  0.00880218],\n",
       "        [-0.00270523,  0.00919028, -0.00500893, ..., -0.00744017,\n",
       "         -0.00373847,  0.00638111],\n",
       "        [-0.00155448,  0.00470958,  0.01261406, ..., -0.00096021,\n",
       "         -0.01647384,  0.0059849 ],\n",
       "        ...,\n",
       "        [-0.00133069,  0.00715045,  0.0028836 , ...,  0.01253994,\n",
       "          0.00179943, -0.0065921 ],\n",
       "        [-0.01062844,  0.01658173, -0.0018872 , ..., -0.00448022,\n",
       "         -0.01040471,  0.00342269],\n",
       "        [-0.01169182,  0.01723223, -0.00309148, ..., -0.011168  ,\n",
       "         -0.00874047,  0.00666463]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32),\n",
       " array([[-0.01612131,  0.01329538,  0.00220527, ..., -0.00593791,\n",
       "          0.00056869, -0.01863154],\n",
       "        [ 0.00466743, -0.00976132,  0.01348363, ...,  0.00442578,\n",
       "          0.00951763,  0.00090636],\n",
       "        [-0.00523073,  0.00760113,  0.01553574, ..., -0.00813315,\n",
       "         -0.01093228, -0.00647176],\n",
       "        ...,\n",
       "        [-0.01598649,  0.02785655,  0.0016065 , ..., -0.00583575,\n",
       "         -0.02948656,  0.01746447],\n",
       "        [ 0.00235166,  0.00524382, -0.00318443, ...,  0.00997554,\n",
       "          0.01361025,  0.00619257],\n",
       "        [ 0.01307517,  0.00484674,  0.00613482, ...,  0.00392045,\n",
       "          0.00199046, -0.00659046]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = keras.Sequential()\n",
    "net.add(keras.layers.Flatten())\n",
    "net.add(keras.layers.Dense(256, activation='relu',kernel_initializer=keras.initializers.RandomNormal(mean=0,stddev=0.01)\n",
    "                           ,bias_initializer=\"zeros\"))\n",
    "net.add(keras.layers.Dense(10,kernel_initializer=keras.initializers.RandomNormal(mean=0,stddev=0.01)))\n",
    "net(X)\n",
    "net.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面使用常数来初始化权重参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32),\n",
       " array([[-0.01213235, -0.00210384,  0.00438292, ..., -0.01069107,\n",
       "         -0.00340701, -0.0071954 ],\n",
       "        [-0.00324624, -0.00025968, -0.01214931, ..., -0.00815848,\n",
       "          0.00584693,  0.01594258],\n",
       "        [ 0.00100125, -0.01333243, -0.01846146, ...,  0.003338  ,\n",
       "         -0.00584654, -0.00655486],\n",
       "        ...,\n",
       "        [ 0.00511306, -0.0103835 ,  0.00646375, ...,  0.00381547,\n",
       "         -0.02004877,  0.0085887 ],\n",
       "        [-0.00549147,  0.01095176,  0.00621002, ...,  0.01865361,\n",
       "         -0.01225346, -0.00573227],\n",
       "        [ 0.01820538,  0.00221616, -0.02310381, ..., -0.00148759,\n",
       "          0.00408682, -0.00418403]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = keras.Sequential()\n",
    "net.add(keras.layers.Flatten())\n",
    "net.add(keras.layers.Dense(256, activation='relu',kernel_initializer=keras.initializers.Constant(1)\n",
    "                           ,bias_initializer=\"zeros\"))\n",
    "net.add(keras.layers.Dense(10,kernel_initializer=keras.initializers.RandomNormal(mean=0,stddev=0.01)))\n",
    "net(X)\n",
    "net.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glorot正态分布初始化方法，也称作`Xavier`正态分布初始化，参数由`0`均值，标准差为`sqrt(2 / (fan_in + fan_out))`的正态分布产生，其中`fan_in`和`fan_out`是权重张量的扇入扇出（即输入和输出单元数目）。下例中我们对隐藏层的权重使用`Xavier`随机初始化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.0695044 , -0.07252984,  0.16599984, ..., -0.01858299,\n",
       "         -0.03362315, -0.13336617],\n",
       "        [ 0.07669634,  0.10013129,  0.02140373, ...,  0.01952465,\n",
       "         -0.11397454,  0.02004574],\n",
       "        [-0.10765048, -0.11513884, -0.03648057, ...,  0.00914257,\n",
       "          0.1434916 ,  0.02981399],\n",
       "        ...,\n",
       "        [ 0.0114043 ,  0.01820433, -0.01351871, ..., -0.12122075,\n",
       "         -0.12489499,  0.06077783],\n",
       "        [ 0.0642491 ,  0.02380809,  0.12315745, ...,  0.10360536,\n",
       "          0.11231796,  0.06345495],\n",
       "        [-0.1374723 ,  0.06293916, -0.09724572, ..., -0.1000086 ,\n",
       "          0.0846191 ,  0.15534091]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32),\n",
       " array([[ 0.00264293, -0.00347834,  0.00327916, ..., -0.01767885,\n",
       "         -0.01256437, -0.01169775],\n",
       "        [ 0.0215631 ,  0.00266198, -0.00447839, ..., -0.00287588,\n",
       "          0.00577132, -0.00973835],\n",
       "        [-0.00634446, -0.00470409, -0.00680865, ...,  0.02744126,\n",
       "          0.00856881, -0.01675703],\n",
       "        ...,\n",
       "        [-0.0144353 ,  0.01149027,  0.01342647, ...,  0.00201086,\n",
       "          0.00147674, -0.01006114],\n",
       "        [ 0.00804592, -0.00072831,  0.01290141, ..., -0.0024554 ,\n",
       "          0.00439221,  0.00145965],\n",
       "        [-0.00833274, -0.00442049,  0.01801909, ..., -0.0084322 ,\n",
       "          0.00693308, -0.00217831]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = keras.Sequential()\n",
    "net.add(keras.layers.Flatten())\n",
    "net.add(keras.layers.Dense(256, activation='relu',kernel_initializer=keras.initializers.GlorotNormal()\n",
    "                           ,bias_initializer=\"zeros\"))\n",
    "net.add(keras.layers.Dense(10,kernel_initializer=keras.initializers.RandomNormal(mean=0,stddev=0.01)))\n",
    "net(X)\n",
    "net.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. 自定义初始化方法\n",
    "可以使用`tf.keras.initializers`类中的方法实现自定义初始化。如果需要传递自定义的初始化器，则该初始化器必须是`callable`的，并且接收`shape`（将被初始化的张量`shape`）和`dtype`（数据类型）两个参数，并返回符合`shape`和`dtype`的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.0890545 ,  0.4419847 , -0.9641655 , ..., -0.12421888,\n",
       "          0.3267785 , -0.6040333 ],\n",
       "        [-1.0615999 , -1.0682908 ,  0.21529667, ..., -0.03203521,\n",
       "          1.9521668 , -0.7281848 ],\n",
       "        [-0.34160733, -0.5677692 , -1.2416878 , ...,  1.0285121 ,\n",
       "          0.43271908,  0.32829037],\n",
       "        ...,\n",
       "        [-1.7969391 ,  0.3126901 ,  0.21185884, ..., -0.24406238,\n",
       "          0.6393728 , -0.0757916 ],\n",
       "        [ 1.8315326 , -1.1442302 , -0.14809616, ...,  1.1795167 ,\n",
       "          0.43464005,  0.06140326],\n",
       "        [ 0.21035595,  0.09683031,  2.2004168 , ...,  1.7135043 ,\n",
       "         -0.45960483,  0.53353256]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32),\n",
       " array([[ 0.01728298,  0.00711452, -0.00846948, ...,  0.01856522,\n",
       "          0.01123955,  0.01325023],\n",
       "        [-0.00350945, -0.00431139,  0.00676259, ...,  0.01152988,\n",
       "          0.01603544,  0.00313546],\n",
       "        [-0.01031263,  0.00973804, -0.00628718, ...,  0.00501588,\n",
       "          0.00757283, -0.00032147],\n",
       "        ...,\n",
       "        [ 0.00917506, -0.0061111 , -0.00310233, ...,  0.00848892,\n",
       "          0.00020598, -0.00490751],\n",
       "        [-0.00840287, -0.00115712, -0.01397359, ...,  0.00791441,\n",
       "          0.00047481,  0.00225521],\n",
       "        [-0.00344022, -0.00508258,  0.02443279, ..., -0.00071885,\n",
       "         -0.00430589, -0.00493252]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def my_init(shape, dtype=None):\n",
    "    return K.random_normal(shape, dtype=dtype)\n",
    "\n",
    "net = keras.Sequential()\n",
    "net.add(keras.layers.Flatten())\n",
    "net.add(keras.layers.Dense(256, activation='relu',kernel_initializer=my_init\n",
    "                           ,bias_initializer=\"zeros\"))\n",
    "net.add(keras.layers.Dense(10,kernel_initializer=keras.initializers.RandomNormal(mean=0,stddev=0.01)))\n",
    "net(X)\n",
    "net.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.1",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
